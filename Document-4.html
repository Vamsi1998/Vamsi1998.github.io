<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>Page 4</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft00{font-size:16px;font-family:Times;color:#000000;}
	.ft01{font-size:16px;font-family:Times;color:#000000;}
	.ft02{font-size:16px;line-height:21px;font-family:Times;color:#000000;}
	.ft03{font-size:16px;line-height:22px;font-family:Times;color:#000000;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page4-div" style="position:relative;width:888px;height:1258px;">
<img width="888" height="1258" src="Document004.png" alt="background image"/>
<p style="position:absolute;top:112px;left:167px;white-space:nowrap" class="ft00">&#160;The&#160;&#160;document&#160;&#160;encoder&#160;&#160;processes&#160;&#160;an&#160;&#160;input&#160;&#160;document,&#160;&#160;generating&#160;&#160;a&#160;&#160;state&#160;&#160;for&#160;</p>
<p style="position:absolute;top:134px;left:135px;white-space:nowrap" class="ft03">each&#160;input&#160;word.&#160;To&#160;get&#160;a&#160;&#160;representation&#160;of&#160;the&#160;&#160;context&#160;around&#160;a&#160;word,&#160;we&#160;&#160;use&#160;a&#160;<br/>bidirectional&#160;RNN&#160;(Schuster&#160;and&#160;Paliwal,&#160;1997)&#160;encoder,&#160;so&#160;both&#160;the&#160;context&#160;before&#160;<br/>and&#160;&#160;after&#160;&#160;contribute&#160;&#160;to&#160;&#160;the&#160;&#160;representation.&#160;&#160;This&#160;&#160;is&#160;&#160;used&#160;&#160;by&#160;&#160;Bahdanau&#160;&#160;et&#160;&#160;al.&#160;&#160;(2015)&#160;<br/>amongst&#160;&#160;others,&#160;&#160;achieving&#160;&#160;good&#160;&#160;results&#160;&#160;on&#160;&#160;a&#160;&#160;similar&#160;&#160;task&#160;&#160;related&#160;&#160;to&#160;&#160;text&#160;<br/>comprehension.&#160;The&#160;combined&#160;RNN&#160;hidden&#160;state&#160;at&#160;time&#160;step&#160;i,The&#160;combined&#160;RNN&#160;<br/>hidden&#160;state&#160;at&#160;time&#160;step&#160;i,&#160;hi&#160;,&#160;and&#160;the&#160;intermediate&#160;states,&#160;&#160;→&#160;hi&#160;and&#160;←&#160;hi&#160;,&#160;from&#160;<br/>the&#160;forward&#160;reader&#160;and&#160;backward&#160;reader&#160;respectively,&#160;are&#160;computed&#160;as&#160;&#160;</p>
<p style="position:absolute;top:407px;left:403px;white-space:nowrap" class="ft00">&#160;</p>
<p style="position:absolute;top:437px;left:135px;white-space:nowrap" class="ft01"><b>Query&#160;Encoder&#160;&#160;</b></p>
<p style="position:absolute;top:471px;left:167px;white-space:nowrap" class="ft00">The&#160;&#160;query&#160;&#160;encoder&#160;&#160;is&#160;&#160;responsible&#160;&#160;for&#160;&#160;creating&#160;&#160;a&#160;&#160;fixed-size&#160;&#160;internal&#160;</p>
<p style="position:absolute;top:493px;left:135px;white-space:nowrap" class="ft02">representation&#160;of&#160;the&#160;input&#160;query.&#160;Unlike&#160;the&#160;document&#160;encoder,&#160;the&#160;query&#160;encoder&#160;<br/>is&#160;&#160;a&#160;&#160;unidirectional&#160;&#160;RNN&#160;&#160;encoder&#160;&#160;since&#160;&#160;queries&#160;&#160;are&#160;&#160;relatively&#160;&#160;short&#160;&#160;compared&#160;&#160;to&#160;<br/>documents&#160;and&#160;we&#160;only&#160;use&#160;the&#160;final&#160;state&#160;to&#160;represent&#160;the&#160;whole&#160;query.&#160;The&#160;RNN&#160;<br/>state&#160;h&#160;Q&#160;i&#160;at&#160;query&#160;word&#160;i,&#160;is&#160;updated&#160;according&#160;to&#160;h&#160;Q&#160;i&#160;=&#160;GRUque(h&#160;Q&#160;i−1&#160;,&#160;E(w&#160;Q&#160;<br/>i&#160;)),&#160;q&#160;=&#160;h&#160;Q&#160;NQ&#160;,&#160;where&#160;w&#160;Q&#160;is&#160;the&#160;input&#160;query&#160;and&#160;NQ&#160;is&#160;the&#160;length&#160;of&#160;the&#160;query.&#160;The&#160;<br/>initial&#160;&#160;state&#160;&#160;h&#160;&#160;Q&#160;&#160;0&#160;&#160;is&#160;&#160;the&#160;&#160;zero&#160;&#160;vector.&#160;&#160;The&#160;&#160;query&#160;&#160;encoder&#160;&#160;state&#160;&#160;dimensionality&#160;&#160;is&#160;<br/>denoted&#160;dque.&#160;&#160;</p>
<p style="position:absolute;top:660px;left:135px;white-space:nowrap" class="ft01"><b>Decoder&#160;&#160;</b></p>
<p style="position:absolute;top:694px;left:167px;white-space:nowrap" class="ft00">The&#160;&#160;decoder&#160;&#160;is&#160;&#160;a&#160;&#160;unidirectional&#160;&#160;RNN&#160;&#160;for&#160;&#160;constructing&#160;&#160;a&#160;&#160;summary&#160;&#160;of&#160;&#160;the&#160;&#160;input&#160;</p>
<p style="position:absolute;top:716px;left:135px;white-space:nowrap" class="ft02">document&#160;by&#160;depending&#160;on&#160;the&#160;final&#160;state&#160;of&#160;the&#160;input&#160;encoder,&#160;the&#160;query.&#160;It&#160;utilizes&#160;<br/>soft&#160;attention,&#160;in&#160;combination&#160;with&#160;a&#160;pointer&#160;mechanism,&#160;as&#160;well&#160;as&#160;a&#160;generator&#160;part&#160;<br/>similar&#160;&#160;to&#160;&#160;Bahdanau&#160;&#160;et&#160;&#160;al.&#160;&#160;(2015).&#160;&#160;The&#160;&#160;query&#160;&#160;embedding&#160;&#160;q&#160;&#160;is&#160;&#160;fed&#160;&#160;as&#160;&#160;input&#160;&#160;at&#160;&#160;each&#160;<br/>decoder&#160;time&#160;step.&#160;This&#160;is&#160;similar&#160;to&#160;the&#160;answering&#160;module&#160;in&#160;a&#160;question&#160;answering&#160;<br/>model&#160;&#160;presented&#160;&#160;by&#160;&#160;Kumar&#160;&#160;et&#160;&#160;al.&#160;&#160;(2016),&#160;&#160;who&#160;&#160;use&#160;&#160;an&#160;&#160;RNN-encoded&#160;&#160;question&#160;<br/>representation&#160;as&#160;input&#160;at&#160;each&#160;decoder&#160;time&#160;step.&#160;In&#160;our&#160;model,&#160;the&#160;RNN&#160;state&#160;is&#160;<br/>updated&#160;according&#160;to&#160;st&#160;=&#160;GRUdec(st−1,&#160;[ct&#160;,&#160;q,&#160;E(yt−1)]),&#160;where&#160;s0&#160;=&#160;hND&#160;,&#160;the&#160;final&#160;<br/>document&#160;encoder&#160;state,&#160;ND&#160;being&#160;the&#160;number&#160;of&#160;input&#160;words;&#160;y0&#160;corresponds&#160;to&#160;a&#160;<br/>special&#160;&#160;token,&#160;&#160;used&#160;&#160;at&#160;&#160;the&#160;&#160;initial&#160;&#160;time&#160;&#160;step&#160;&#160;when&#160;&#160;no&#160;&#160;previous&#160;&#160;word&#160;&#160;has&#160;&#160;been&#160;<br/>predicted;&#160;&#160;ct&#160;&#160;is&#160;&#160;the&#160;&#160;context&#160;&#160;vector&#160;&#160;at&#160;&#160;time&#160;&#160;step&#160;&#160;t&#160;&#160;from&#160;&#160;the&#160;&#160;attention&#160;&#160;mechanism,&#160;<br/>defined&#160;subsequently;&#160;and&#160;yt−1&#160;∈&#160;V&#160;is&#160;the&#160;predicted&#160;output&#160;word&#160;at&#160;time&#160;step&#160;t&#160;−&#160;1.&#160;<br/>This&#160;&#160;is&#160;&#160;either&#160;&#160;from&#160;&#160;the&#160;&#160;generator&#160;&#160;mechanism,&#160;&#160;or&#160;&#160;the&#160;&#160;pointer&#160;&#160;mechanism,&#160;&#160;also&#160;<br/>defined&#160;&#160;subsequently.&#160;&#160;The&#160;&#160;word&#160;&#160;embeddings&#160;&#160;are&#160;&#160;the&#160;&#160;same&#160;&#160;as&#160;&#160;are&#160;&#160;used&#160;&#160;in&#160;&#160;the&#160;<br/>encoder.The&#160;&#160;model&#160;&#160;has&#160;&#160;a&#160;&#160;soft&#160;&#160;attention&#160;&#160;mechanism,&#160;&#160;based&#160;&#160;on&#160;&#160;one&#160;&#160;used&#160;&#160;by&#160;<br/>Bahdanau&#160;&#160;et&#160;&#160;al.&#160;&#160;(2015)&#160;&#160;for&#160;&#160;machine&#160;&#160;translation.&#160;&#160;The&#160;&#160;result&#160;&#160;of&#160;&#160;the&#160;&#160;attention&#160;<br/>mechanism&#160;is&#160;a&#160;context&#160;vector&#160;ct&#160;produced&#160;at&#160;each&#160;time&#160;step&#160;t,&#160;computed&#160;as&#160;</p>
</div>
</body>
</html>
